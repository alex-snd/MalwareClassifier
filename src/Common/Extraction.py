import json
from multiprocessing import Manager, Process

import pandas as pd

from src.Common import ExtractionFunctions
from src.Common import config
from src.Common.SharedMemory import SharedFeatureVec, SharedExtractionFunctions
from src.Common.utils import get_data_base, get_data_base_path, get_target_file_paths


class FeatureExtractor(object):
    def __init__(self, num_processes: int = 6) -> None:
        self._num_processes = num_processes
        self._extraction_functions = self._get_extraction_functions()
        self._manager = Manager()

    @staticmethod
    def _get_extraction_functions() -> list:
        all_functions = dir(ExtractionFunctions)
        extraction_functions = list()

        for function in all_functions:
            if function.startswith('extract_'):
                extraction_functions.append(eval(f'code.Common.ExtractionFunctions.{function}'))

        return extraction_functions

    def _extract_by_one_process(self, data: dict) -> list:
        feature_vec = SharedFeatureVec(self._manager)

        for function in self._extraction_functions:
            function(feature_vec, data)

        return feature_vec.get_vec()

    def _extract(self, data: dict) -> list:
        """Bad performance"""

        try:
            data = self._manager.dict(data)
            feature_vec = SharedFeatureVec(self._manager)
            shared_extraction_functions = SharedExtractionFunctions(self._extraction_functions.copy(), self._manager)

            while shared_extraction_functions:
                processes = list()

                while shared_extraction_functions and len(processes) < self._num_processes:
                    function = shared_extraction_functions.get_function()
                    processes.append(Process(target=function, args=(feature_vec, data)))

                for process in processes:
                    process.start()

                for process in processes:
                    process.join()

            return feature_vec.get_vec()

        except RecursionError as e:
            print(f'[_extract]: {e}')
            return self._extract_by_one_process(data)

    def get_features(self, data: dict) -> list:
        # return self._extract(data)
        return self._extract_by_one_process(data)


class LabelExtractor(object):
    #             0         1          2              3                 4              5
    labels = [r'Trojan', r'Virus', r'Worm', r'not-a-virus:AdWare', r'Backdoor', r'Trojan-Ransom',
              #           6                7
              r'not-a-virus:RiskTool', r'Packed']

    def __init__(self, target_path: str = config.target_path, num_processes: int = 12) -> None:
        self.target_info = self._prepare_target_files(get_target_file_paths(target_path))
        self._num_processes = num_processes
        self._manager = Manager()

    @staticmethod
    def _prepare_target_files(target_paths: list) -> dict:
        target_info = dict()

        for trg_file in target_paths:
            info = list()

            with open(trg_file) as j_f:
                target_data = json.load(j_f)

            ExtractionFunctions.deepening(info, target_data, way=('sha256',))
            ExtractionFunctions.deepening(info, target_data, way=('scans', (), 'Kaspersky', 'result'))

            if len(info) == 1:
                info.append('NONE')

            target_info[info[0]] = info[1].split('.')[0]

        return target_info

    def _labeling(self, data_base: pd.DataFrame,
                  heuristics: bool) -> (pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame, set):

        unlabeled = pd.DataFrame()
        heuristic = pd.DataFrame()
        unknown = pd.DataFrame()
        unlabeled_hashes = list()
        dropping = list()
        n = len(self.labels)

        for i in data_base.index:
            i_hash = data_base.iloc[i]['0']

            if i_hash in self.target_info and self.target_info[i_hash] != 'NONE':
                i_label = self.target_info[i_hash].replace('HEUR:', '') if heuristics else self.target_info[i_hash]

                if i_label in self.labels:
                    data_base.loc[i, '1'] = self.labels.index(i_label)
                    continue

                if 'HEUR:' not in i_label and 'Trojan' in i_label:
                    data_base.loc[i, '1'] = self.labels.index('Trojan')
                    continue

                if 'HEUR:' not in i_label and 'Worm' in i_label:
                    data_base.loc[i, '1'] = self.labels.index('Worm')
                    continue

                if not heuristics and 'HEUR:' in i_label:
                    heuristic = heuristic.append(data_base.iloc[i].copy())
                    dropping.append(i)
                    continue

                data_base.loc[i, '1'] = n  # unknown
                unknown = unknown.append(data_base.iloc[i].copy())
                dropping.append(i)

            else:
                unlabeled = unlabeled.append(data_base.iloc[i].copy())
                unlabeled_hashes.append(i_hash)
                dropping.append(i)
                # print(self.target_info[i_hash])

        for i in dropping:
            data_base.drop(i, inplace=True)

        return data_base, heuristic, unknown, unlabeled, set(unlabeled_hashes)

    def get_labeled_data_base(self, data_base_file: str,
                              heuristics: bool) -> (pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame, set):
        data_base = get_data_base(data_base_file, labels=True)

        return self._labeling(data_base, heuristics)


def feature_extractor_testing():
    json_filename = 'path/to/example'

    with open(json_filename) as j_f:
        _json_data = json.load(j_f)

    extractor = FeatureExtractor(num_processes=12)

    extracted_features = extractor.get_features(_json_data)

    ln = 65
    n = 3691
    for i in range(n):
        print(f'{i:>{ln}} ', end='')
    print()

    for i in extracted_features:
        print(f'{i:>{ln}} ', end='')

    print('\n', sum(extracted_features[1:]))


def label_extracting_testing():
    label_extractor = LabelExtractor()

    table = label_extractor.get_labeled_data_base(data_base_file=get_data_base_path('database.csv'),
                                                  heuristics=False)

    for r in table:
        print(r.shape)


if __name__ == '__main__':
    feature_extractor_testing()

    pass
