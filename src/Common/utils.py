import json
from datetime import datetime
from os import listdir, mkdir, makedirs
from os.path import join, basename, dirname, exists, isfile
from shutil import move

import pandas as pd

from src.Common import config


def check_torch() -> None:
    import torch

    print(torch.cuda.is_available())

    print(torch.cuda.get_device_name())
    print(torch.cuda.get_device_properties(0))


def save_obj(obj: object, filename: str) -> None:
    with open(join(config.parameters_path, filename), 'wb') as storage:
        json.dump(obj, storage)


def get_report_paths(paths: tuple = (config.reports_path,)) -> list:
    report_paths = list()

    for path in paths:
        for report in [join(path, part_path) for part_path in listdir(path)]:
            if isfile(report):
                report_paths.append(report)

    return report_paths[::-1]


def get_debug_report_paths() -> list:
    return get_report_paths((config.debug_reports_path,))


def get_target_file_paths(path: str = config.target_path) -> list:
    return get_report_paths((path,))


def get_file_id(path: str) -> int:
    return len(listdir(path))


def get_time_id(seconds: bool = False) -> str:
    if seconds:
        return datetime.now().strftime('%m_%d__%H_%M_%S')
    else:
        return datetime.now().strftime('%m_%d__%H_%M')


def get_seen_hashes(filename: str = join(config.parameters_path, 'hashes')) -> dict:
    try:
        with open(filename, 'rb') as obj:
            return json.load(obj)
    except FileNotFoundError as e:
        print(f'[get_seen_hashes]: {e}')
        return dict()


def get_data_base(filename: str, labels: bool = True) -> pd.DataFrame:
    data_base = pd.read_csv(join(config.data_base_path, filename))

    if not labels:
        data_base = data_base.drop(data_base.columns[:2], axis=1)

    return data_base


def get_train_data_base(filename: str, labels: bool = False) -> pd.DataFrame:
    return get_data_base(join(config.train_data_base_path, filename), labels)


def get_validation_data_base(filename: str, labels: bool = False) -> pd.DataFrame:
    return get_data_base(join(config.validation_data_base_path, filename), labels)


def get_test_data_base(filename: str, labels: bool = False) -> pd.DataFrame:
    return get_data_base(join(config.test_data_base_path, filename), labels)


def get_data_base_path(filename: str) -> str:
    return join(config.data_base_path, filename)


def get_train_data_base_path(filename: str) -> str:
    return join(config.train_data_base_path, filename)


def get_validation_data_base_path(filename: str) -> str:
    return join(config.validation_data_base_path, filename)


def get_test_data_base_path(filename: str) -> str:
    return join(config.test_data_base_path, filename)


def get_ae_latent_data_base_path(filename: str) -> str:
    return join(config.ae_latent_data_base_path, filename)


def get_ae2_latent_data_base_path(filename: str) -> str:
    return join(config.ae2_latent_data_base_path, filename)


def get_check_point_parameters_path(path: str, file_id: int = 0) -> str:
    return join(path, listdir(path)[file_id])


def data_base_to_x_y(data: pd.DataFrame) -> (pd.DataFrame, pd.DataFrame):
    col = data.columns
    return data.loc[:, col[2:]], data.loc[:, col[1]]


def create_dir(path: str) -> None:
    if not exists(path):
        makedirs(path)


def create_training_space(model_name: str, evaluate: bool = False) -> dict:
    model_path = join(config.models, model_name)
    create_dir(model_path)

    mark = get_time_id()
    file_id = get_file_id(model_path)

    current_model_path = join(model_path, f'{model_name}_{mark}__{file_id}')

    training_space = dict()

    training_space['check_point'] = join(model_path, '{check_point}')
    training_space['parameters'] = join(current_model_path, 'parameters')
    training_space['loss'] = join(current_model_path, 'loss')
    training_space['performance'] = join(current_model_path, 'performance')
    training_space['latent_space'] = join(current_model_path, 'latent_space')

    if not evaluate:
        for path in training_space.values():
            create_dir(path)

    training_space['mark'] = f'{mark}__{file_id}'
    training_space['log'] = join(current_model_path, f'log___{training_space["mark"]}.txt')

    return training_space


def move_to(file_path: str, folder: str) -> None:
    try:
        path_to_dirty = join(dirname(file_path), folder)
        if not exists(path_to_dirty):
            mkdir(path_to_dirty)

        new_file_path = join(path_to_dirty, basename(file_path))
        move(file_path, new_file_path)
    except Exception as e:
        print(f'{file_path} was not moved to {folder} due to error: {e}')
    else:
        print(f'{file_path} was moved to {folder}')


def move_to_dirty(file_path: str) -> None:
    move_to(file_path, 'dirty')


def move_to_info_lack(file_path: str) -> None:
    move_to(file_path, 'info_lack')


def move_to_duplicates(file_path: str, same_with_file_path: str) -> None:
    try:
        path_to_duplicates = join(dirname(file_path), 'duplicates')
        if not exists(path_to_duplicates):
            mkdir(path_to_duplicates)

        js_filename = basename(file_path)
        new_js_filename = f'{js_filename.split(".")[0]} same with {basename(same_with_file_path)}'
        new_file_path = join(path_to_duplicates, new_js_filename)

        move(file_path, new_file_path)
    except Exception as e:
        print(f'{file_path} was not moved to duplicates due to error: {e}')
    else:
        print(f'{file_path} was moved to duplicates')


def enough_info(data: dict) -> bool:
    if 'info' not in data.keys():
        return False
    if 'signatures' not in data.keys():
        return False
    if 'target' not in data.keys():
        return False
    if 'network' not in data.keys():
        return False
    if 'static' not in data.keys():
        return False
    if 'behavior' not in data.keys():
        return False
    if 'strings' not in data.keys():
        return False

    return True


if __name__ == '__main__':
    pass
