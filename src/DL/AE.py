from os.path import join

import matplotlib
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import torch
from matplotlib import cm
from torch import nn, optim
from torch.nn import functional as F
from torch.optim import lr_scheduler
from torch.utils.data import DataLoader

from src.Common import config
from src.Common.Extraction import LabelExtractor
from src.Common.utils import (get_train_data_base_path, get_validation_data_base_path, create_training_space,
                              get_check_point_parameters_path, get_test_data_base_path)
from src.DB.Datasets import UnLabeledDataSet, LabeledDataSet, EntireDataSet
from src.DL.utils import loss_visualization, save_parameters, array_to_image


class AE(nn.Module):
    def __init__(self, d_in: int, d_l: int):
        super(AE, self).__init__()

        self.d_in = d_in
        self.d_l = d_l

        # encoder
        self.en_fc1 = nn.Linear(self.d_in, d_l)

        # decoder
        self.dec_fc1 = nn.Linear(d_l, d_in)

    def encode(self, x):
        return F.relu(self.en_fc1(x))

    def decode(self, z):
        return torch.sigmoid(self.dec_fc1(z))

    def forward(self, x):
        z = self.encode(x.view(-1, self.d_in))

        return self.decode(z)

    def save_parameters(self, filename: str):
        torch.save(self.state_dict(), filename)

    def load_parameters(self, filename: str, device: torch.device):
        self.load_state_dict(torch.load(filename, map_location=device))


def epoch_training(i_epoch: int, model: nn.Module, train_loader: DataLoader, optimizer, device: torch.device,
                   loss_function: eval, log_interval: int, training_space: dict, loss_history: dict,
                   printable: bool = True) -> None:
    model.train()
    train_loss = 0
    batch_idx = 1

    for batch_idx, data in enumerate(train_loader, start=1):
        data = data.to(device)

        optimizer.zero_grad()

        recon_batch = model(data)

        loss = loss_function(recon_batch, data)
        loss.backward()
        train_loss += loss.item()

        optimizer.step()

        if batch_idx % log_interval == 0:
            i_epoch_loss = loss.item()
            i_epoch_info = f'Train Epoch: {i_epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} ' \
                           f'{100. * batch_idx / len(train_loader):.0f}%)]\tLoss: {i_epoch_loss:.6f}'

            if printable:
                print(i_epoch_info)

            loss_history['loss'].append(i_epoch_loss)

            with open(training_space['log'], 'a') as logger:
                logger.write(i_epoch_info + '\n')

    avg_epoch_loss = train_loss / batch_idx
    epoch_info = f'====> Epoch: {i_epoch} Average loss: {avg_epoch_loss:.4f}'

    if printable:
        print(epoch_info)

    loss_history['avg_loss'].append(avg_epoch_loss)

    with open(training_space['log'], 'a') as logger:
        logger.write(epoch_info + '\n')


def epoch_validation(model: nn.Module, validation_loader: DataLoader, device: torch.device, loss_function: eval,
                     training_space: dict, loss_history: dict, printable: bool = True) -> None:
    model.eval()
    validation_loss = 0
    n_batches = 0

    with torch.no_grad():
        for i, data in enumerate(validation_loader, start=1):
            data = data.to(device)

            recon_batch = model(data)

            validation_loss += loss_function(recon_batch, data).item()

            n_batches = i

    validation_loss /= n_batches
    validation_info = f'====> Validation loss: {validation_loss:.4f}\n'

    loss_history['valid_loss'].append(validation_loss)

    if printable:
        print(validation_info)

    with open(training_space['log'], 'a') as logger:
        logger.write(validation_info + '\n')


def epoch_visualization(training_space: dict, loss_history: dict, model: nn.Module, i_epoch: int,
                        scatter_data_base: DataLoader, performance_data_base: UnLabeledDataSet,
                        device: torch.device) -> None:
    loss_visualization(training_space, loss_history, i_epoch)
    ae_performance(training_space, model, performance_data_base, i_epoch, device)

    if model.d_l == 2:
        ae_scatter_latent_space(training_space, model, scatter_data_base, i_epoch, device)


def ae_performance(training_space: dict, model: nn.Module, performance_data_base: UnLabeledDataSet, i_epoch: int,
                   device: torch.device, n_to_show: int = 5) -> None:
    def save_performance(_image: np.array, _i: int, _i_epoch: int) -> None:
        plt.set_cmap('GnBu')
        plt.figure(figsize=(19.2, 10.8))
        plt.axis('off')
        plt.tight_layout()
        plt.imshow(_image)
        plt.savefig(join(training_space['performance'], f'{_i}_epoch_{_i_epoch}.png'), dpi='figure', format='png',
                    bbox_inches='tight')

        plt.clf()
        plt.close('all')

    model.eval()

    images = list()
    n = len(performance_data_base) if len(performance_data_base) < n_to_show else n_to_show
    width = 10

    for i, i_sample in enumerate(performance_data_base):
        if i == n_to_show:
            break

        i_sample = torch.tensor(i_sample).to(device)
        i_decoded = model(i_sample.view(-1, i_sample.shape[0]))

        i_sample = array_to_image(i_sample.cpu().numpy())
        i_decoded = array_to_image(i_decoded.detach().cpu().numpy())
        i_diff = np.abs(i_sample - i_decoded)

        im_size = i_sample.shape[0]

        image = np.zeros((im_size, 3 * im_size + 2 * width))

        image[:, :im_size] = i_sample
        image[:, im_size + width: 2 * im_size + width] = i_decoded
        image[:, 2 * im_size + 2 * width:] = i_diff

        images.append(image)

        save_performance(image, i, i_epoch)

    im_h = images[0].shape[0]
    im_w = images[0].shape[1]
    width = 5

    image = np.zeros((n * im_h + (n - 1) * width, im_w))

    for i in range(n):
        image[i * im_h + i * width: (i + 1) * im_h + i * width, :] = images[i]

    save_performance(image, n, i_epoch)


def ae_scatter_latent_space(training_space: dict, model: nn.Module, scatter_loader: DataLoader, i_epoch: int,
                            device: torch.device) -> None:
    model.eval()

    n = len(scatter_loader.dataset)
    dots = np.zeros((n, 2))

    for i, i_sample in enumerate(scatter_loader):
        i_sample = i_sample.type(torch.float32).to(device)
        i_encoded = model.encode(i_sample)

        batch_size = i_encoded.shape[0]
        dots[i * batch_size: (i + 1) * batch_size, :] = i_encoded.detach().cpu().numpy()

    fig, ax = plt.subplots(figsize=(19.2, 10.8))
    ax.scatter(dots[:, 0], dots[:, 1], c='lightseagreen', marker='.')
    ax.set_title(f'Latent space')
    fig.tight_layout()
    plt.savefig(join(training_space['latent_space'], f'scatter_epoch_{i_epoch}.png'), dpi='figure', format='png',
                bbox_inches='tight')

    plt.clf()
    plt.close('all')


def ae_scatter_labeled_latent_space(training_space: dict, model: nn.Module, labeled_scatter_loader: DataLoader,
                                    device: torch.device, n_to_show: int = 1000) -> None:
    model.eval()

    if n_to_show > len(labeled_scatter_loader.dataset):
        n_to_show = len(labeled_scatter_loader.dataset)

    dots = np.zeros((n_to_show, 2))
    labels = []

    for i, (i_sample, i_label) in enumerate(labeled_scatter_loader):
        if i == n_to_show:
            break

        i_sample = i_sample.type(torch.float32).to(device)
        i_encoded = model.encode(i_sample)

        batch_size = i_encoded.shape[0]
        dots[i * batch_size: (i + 1) * batch_size, :] = i_encoded.detach().cpu().numpy()
        labels.extend(list(i_label))

    ticks_names = LabelExtractor.labels
    color_len = max(labels) / len(ticks_names)
    ticks = list(np.arange(color_len / 2, len(ticks_names) * color_len, color_len))

    color_map = cm.get_cmap('rainbow', len(ticks_names))

    fig, ax = plt.subplots(figsize=(19.2, 10.8))
    scatter = ax.scatter(dots[:, 0], dots[:, 1], c=labels, cmap=color_map, marker='o', alpha=1.0)
    color_bar = fig.colorbar(scatter, ticks=ticks, ax=ax, drawedges=True)
    color_bar.ax.set_yticklabels(ticks_names)
    ax.set_title(f'Latent space')
    fig.tight_layout()
    plt.savefig(join(training_space['latent_space'], f'labeled_scatter.png'), dpi='figure', format='png',
                bbox_inches='tight')

    plt.clf()
    plt.close('all')


def data_base_to_ae_latent(data_base: EntireDataSet, model: nn.Module, device: torch.device,
                           batch_size: int = 512) -> None:
    loader = DataLoader(data_base, batch_size=batch_size, shuffle=False, num_workers=1, pin_memory=True)

    samples = list()
    hashes = list()
    labels = list()

    for sample, mark in loader:
        hashes += mark[0]
        labels += list(mark[1])

        sample = model.encode(sample.to(device))
        samples.append(sample.detach().cpu())

    marks = list()
    for i in range(len(hashes)):
        marks.append([hashes[i], int(labels[i])])

    marks = pd.DataFrame(marks)
    samples = torch.cat(samples).numpy()
    samples = pd.DataFrame(samples)

    data_base = pd.concat([marks, samples], axis=1, ignore_index=True)

    data_base.to_csv(path_or_buf=join(config.ae_latent_data_base_path,
                                      f'AE_{model.d_l}_latent__{data_base.data_base_file}'), index=False)

    print(f'Data base shape: {data_base.shape}')


def training() -> None:
    torch.manual_seed(2531)
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    batch_size = 512
    n_epochs = 40
    lr = 1e-3
    lr_step_interval = 30
    pre_trained = False

    log_interval = 3
    saving_interval = 10
    visualization_interval = 1

    train_data_base = get_train_data_base_path('train.csv')
    validation_data_base = get_validation_data_base_path('validation.csv')
    test_data_base = get_test_data_base_path('test.csv')

    train_data_set = UnLabeledDataSet(train_data_base)
    validation_data_set = UnLabeledDataSet(validation_data_base)
    test_data_set = UnLabeledDataSet(test_data_base)
    test_labeled_data_set = LabeledDataSet(test_data_base)

    train_loader = DataLoader(train_data_set, batch_size=batch_size, shuffle=True, num_workers=1)
    validation_loader = DataLoader(validation_data_set, batch_size=batch_size, shuffle=False, num_workers=1)
    test_loader = DataLoader(test_data_set, batch_size=batch_size, shuffle=False, num_workers=1)
    test_labeled_loader = DataLoader(test_labeled_data_set, batch_size=batch_size, shuffle=False, num_workers=1)

    training_space = create_training_space(model_name='AE')

    d_in = train_data_set.sample_size
    d_l = 600

    model = AE(d_in=d_in, d_l=d_l).to(device)

    if pre_trained:
        model.load_parameters(get_check_point_parameters_path(training_space['check_point']), device=device)

    loss_function = nn.BCELoss(reduction='mean')
    optimizer = optim.Adam(model.parameters(), lr=lr)
    ae_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=lr_step_interval)

    with open(training_space['log'], 'w') as logger:
        logger.write(train_data_base + '\n')
        logger.write(validation_data_base + '\n')
        logger.write(f'batch size: {batch_size}\n')
        logger.write(f'n_epochs: {n_epochs}\n')
        logger.write(f'lr: {lr}\n')
        logger.write(f'lr_step_interval: {lr_step_interval}\n')
        logger.write(f'pre_trained: {pre_trained}\n')
        logger.write(str(model))
        logger.write(f'\n{optimizer}\n')

    loss_history = {'loss': [], 'avg_loss': [], 'valid_loss': []}

    try:
        for i_epoch in range(1, n_epochs + 1):
            epoch_training(i_epoch, model, train_loader, optimizer, device, loss_function, log_interval,
                           training_space,
                           loss_history)
            epoch_validation(model, validation_loader, device, loss_function, training_space, loss_history)

            if i_epoch % saving_interval == 0:
                save_parameters(model, training_space, i_epoch)

            if i_epoch % visualization_interval == 0:
                epoch_visualization(training_space, loss_history, model, i_epoch, test_loader,
                                    test_data_set, device)

            ae_lr_scheduler.step()

        if model.d_l == 2:
            ae_scatter_labeled_latent_space(training_space, model, test_labeled_loader, device)

    except KeyboardInterrupt:
        print('Interrupted')


if __name__ == '__main__':
    matplotlib.rcParams.update({'font.size': 22})

    training()

    pass
